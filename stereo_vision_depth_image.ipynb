{"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"3EQPBCCIOm7T"}},{"cell_type":"markdown","source":["ENPM673: Perception for Autonomous Robots\n","\n","By: Shivam Dhakad\n","\n","Problem1 Dataset: https://drive.google.com/drive/folders/1QRWZaUvkLn_vJQq0bPVQhtoK0c44-Otx?usp=sharing"],"metadata":{"id":"CxGbs2JqOa4s"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25748,"status":"ok","timestamp":1713491991911,"user":{"displayName":"Shivam Dhakad","userId":"05137417545652688773"},"user_tz":240},"id":"w_CPwfRskOVA","outputId":"d073276a-379f-4b60-ba30-42d7b6362691"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive\n","/content/drive/My Drive/ENPM673/project3\n"]}],"source":["#mounting the drive\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    FOLDERNAME =  \"ENPM673/project3/\"\n","    assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","    %cd drive/My\\ Drive\n","    %cd $FOLDERNAME\n","except ModuleNotFoundError as ex:\n","    print(\"Please run this snippet in Google Colab\")"]},{"cell_type":"code","source":["# Import Libraries\n","import numpy as np\n","import cv2 as cv\n","from matplotlib import pyplot as plt\n","import os\n","import glob\n","from time import sleep"],"metadata":{"id":"2KfvT_gROucg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Pipeline for Stereo Vision System\n"],"metadata":{"id":"xfY5Wc2xJyLV"}},{"cell_type":"code","source":["# input camera properties\n","\n","# classroom camera\n","# K camera matrix for classroom dataset\n","C_K1=np.array([[1746.24, 0, 14.88],[ 0, 1746.24 , 534.11],[0, 0 ,1]])     # input\n","C_K2=np.array([[1746.24 ,0 ,14.88],[0, 1746.24 , 534.11],[ 0 ,0, 1]])  # input\n","\n","doffs=0\n","C_baseline=678.37   #input\n","width=1920\n","height=1080\n","C_ndisp=310 # input  #conservative bound on the number of disparity levels\n","C_vmin=60 # input    # tight bound on minimum and maximum disparities\n","C_vmax=280  # input    #tight bound on minimum and maximum disparities\n","C_dataset_no = 1\n","C_calib_properties = [C_K1,C_K2,C_baseline, C_ndisp,C_vmin, C_vmax,1]\n","\n","# storage camera\n","S_K1 = np.array([[1742.11 , 0 ,804.90],[ 0 ,1742.11, 541.22],[ 0 ,0, 1]])# input\n","S_K2 = np.array([[1742.11, 0 ,804.90],[ 0 ,1742.11, 541.22],[ 0 ,0 ,1]])# input\n","\n","doffs=0\n","S_baseline=221.76\n","width=1920\n","height=1080\n","S_ndisp=100\n","S_vmin=29\n","S_vmax=61\n","S_dataset_no = 1\n","S_calib_properties = [S_K1, S_K2, S_baseline, S_ndisp, S_vmin, S_vmax,2]\n","\n","# trapzone camera\n","T_K1 = np.array([[1769.02, 0 ,1271.89],[0 ,1769.02, 527.17],[ 0, 0 ,1]]) # input\n","T_K2 = np.array([[1769.02 ,0, 1271.89],[ 0, 1769.02 ,527.17],[0 ,0, 1]])# input\n","\n","doffs=0\n","T_baseline=295.44\n","T_width=1920\n","T_height=1080\n","T_ndisp=140\n","T_vmin=25\n","T_vmax=118\n","T_dataset_no = 3\n","T_calib_properties = [T_K1, T_K2, T_baseline, T_ndisp, T_vmin, T_vmax,3]\n","\n","calib_properties_list=[C_calib_properties,S_calib_properties,T_calib_properties]\n"],"metadata":{"id":"SGdRyBTeJ7Ez"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load images from dataset\n","\n","# Define the base folder path (replace with yours)\n","base_folder1 = \"problem2_dataset/classroom\"\n","base_folder2 = \"problem2_dataset/traproom\"\n","base_folder3 = \"problem2_dataset/storageroom\"\n","\n","Cimage1_path = f\"{base_folder1}/im0.png\"  # Combine path with filename\n","Cimage2_path = f\"{base_folder1}/im1.png\"\n","\n","Simage1_path = f\"{base_folder2}/im1.png\"\n","Simage2_path = f\"{base_folder2}/im0.png\"\n","\n","Timage1_path = f\"{base_folder3}/im0.png\"\n","Timage2_path = f\"{base_folder3}/im1.png\"\n","image_list = []  # list to store image dataset\n","\n","dataset_list = [Cimage1_path,Cimage2_path],[Simage1_path,Simage2_path],[Timage1_path,Timage2_path]\n","for dataset in dataset_list:\n","    image1_path,image2_path = dataset\n","    # print(\"\")\n","    img1 = cv.imread(image1_path)[:,:,:3]  # Read ignoring alpha channel\n","    img1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)\n","    img2 = cv.imread(image2_path)[:,:,:3]\n","    img2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)\n","    image_list.append([img1,img2])\n","    # plt.figure(figsize=(25 , 10))  # Adjust width and height as desired\n","    # plt.subplot(121),plt.imshow(img1)\n","    # plt.subplot(122),plt.imshow(img2)\n","    # plt.show()\n"],"metadata":{"id":"pAuhlON6KBLk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## pipeline\n","\n","# FUNCTION: STEREO_VISION PIPELINE\n","\n","def pipeline_stereovision(img1,img2,K1,K2,baseline, ndisp,vmin,vmax):\n","\n","  #plotting origianl dataset images\n","  plt.figure(figsize=(25 , 10))  # Adjust width and height as desired\n","  plt.subplot(121),plt.title('orignal_image1'),plt.imshow(img1)\n","  plt.subplot(122),plt.title('original_image2'),plt.imshow(img2)\n","  plt.show()\n","\n","  # feature detector\n","  sift = cv.SIFT_create()\n","\n","  # find the keypoints and descriptors with SIFT\n","  kp1, des1 = sift.detectAndCompute(img1,None)\n","  kp2, des2 = sift.detectAndCompute(img2,None)\n","\n","  # FLANN parameters\n","  FLANN_INDEX_KDTREE = 1\n","  index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n","  search_params = dict(checks=50)\n","  # feature points matching method\n","  flann = cv.FlannBasedMatcher(index_params,search_params)\n","  matches = flann.knnMatch(des1,des2,k=2)\n","\n","  pts1 = [] #feature points of image1\n","  pts2 = []  #feature point of image2\n","\n","  # ratio test as per Lowe's paper\n","  for i,(m,n) in enumerate(matches):\n","    if m.distance < 0.60*n.distance:\n","        pts2.append(kp2[m.trainIdx].pt)\n","        pts1.append(kp1[m.queryIdx].pt)\n","\n","  # Now we have the list of best matches from both the images. Let's find the Fundamental Matrix.\n","  pts1 = np.int32(pts1)\n","  pts2 = np.int32(pts2)\n","  F, mask = cv.findFundamentalMat(pts1,pts2,cv.FM_LMEDS)\n","  print(\"Fundamental_matrix:\",\"\\n\",F)\n","\n","  # select inlier points\n","  pts1 = pts1[mask.ravel()==1]\n","  pts2 = pts2[mask.ravel()==1]\n","\n","\n","  # Function to draw corner points and line connecting them\n","  def drawlines(img1,img2,lines,pts1,pts2):\n","    ##''' img1 - image on which we draw the epilines for the points in img2 lines - corresponding epilines '''\n","    r,c = img1.shape\n","    img1 = cv.cvtColor(img1,cv.COLOR_GRAY2BGR)\n","    img2 = cv.cvtColor(img2,cv.COLOR_GRAY2BGR)\n","    for r,pt1,pt2 in zip(lines,pts1,pts2):\n","      color = tuple(np.random.randint(0,255,3).tolist())\n","      x0,y0 = map(int, [0, -r[2]/r[1] ])\n","      x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n","      img1 = cv.line(img1, (x0,y0), (x1,y1), color,1)\n","      img1 = cv.circle(img1,tuple(pt1),5,color,-1)\n","      img2 = cv.circle(img2,tuple(pt2),5,color,-1)\n","    return img1,img2\n","\n","\n","  # draw epilines corresponding to the points in image 2 and\n","  # draw epilines on image1 based on feature points in image2\n","  lines1 = cv.computeCorrespondEpilines(pts2.reshape(-1,1,2), 2,F)\n","  lines1 = lines1.reshape(-1,3)\n","  img5,img6 = drawlines(img1,img2,lines1,pts1,pts2)\n","  # draw epilines on image2 based on feature points in image1\n","  lines2 = cv.computeCorrespondEpilines(pts1.reshape(-1,1,2), 1,F)\n","  lines2 = lines2.reshape(-1,3)\n","  img3,img4 = drawlines(img2,img1,lines2,pts2,pts1)\n","\n","  plt.figure(figsize=(25 , 10))  # Adjust width and height as desired\n","  plt.subplot(121),plt.title('image1 feature point and epilines'),plt.imshow(img5)\n","  plt.subplot(122),plt.title('image1 feature point and epilines'),plt.imshow(img3)\n","  plt.show()\n","\n","\n","  # calculate essential matrix, rotational and translation matrix for two image planes\n","  # K1: Camera matrix for the first image.\n","  # K2: Camera matrix for the second image.\n","  # R: Rotation matrix between the cameras.\n","  # t1: Translation vector between the cameras.\n","  # baseline: distance between two cameras centers.\n","\n","  # Essential matrix\n","  E = K1.T @ F @ K2\n","  print(\"Essential_matrix(E):\",\"\\n\",E)\n","  # Perform SVD on the essential matrix\n","  U, S, VT = np.linalg.svd(E)\n","\n","  # Enforce the smallest singular value to be close to zero\n","  S[2] = 0\n","\n","  # Recover rotation matrix from SVD components\n","  W = np.array([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\n","  R = U @ W @ VT.T\n","\n","  # There are two possible solutions for translation due to depth ambiguity\n","  t1 = U[:, 2]  # first solution\n","  t2 = -U[:, 2]  # second solution (opposite direction)\n","\n","  #print E , R, t1 matrix\n","  print(\"Rotation_matrix (R):\")\n","  # R= np.reshape(R, (3, 3))\n","  R = np.array(R)\n","  print(R)\n","  print(\"\\nTranslation_Vector (t1):\")\n","  print(t1)\n","  if t1.shape != (3, 1):\n","    # print(\"t1_reshaped:\",t1)\n","    t1 = np.reshape(t1, (3, 1))  # Reshape to (3x1)\n","  K1 = np.array(K1)\n","  print(\"K1_matrix\",K1)\n","  K2 = np.reshape(K2, (3, 3))\n","  print(\"K2_matrix\",K2)\n","\n","  #calculating homegraphy matrix between image1 and image2\n","  imageSize = img1.shape[:2]\n","  # calculating homography matrix to rectify the image_set\n","  _, H1, H2 = cv.stereoRectifyUncalibrated(pts1, pts2, F, (1920, 1080))\n","\n","  #visulaze the results\n","  print(\"Homography Matrix H1:\", H1)\n","  print(\"Homography Matrix H2:\",H2)\n","\n","\n","  # rectification tranformation map for both images\n","  image_size = img1.shape[:2]  # Extract width and height\n","  dist_coeffs=0\n","\n","  # Rectify the image\n","  rectified_image1 = cv.warpPerspective(img1, H1, (1920, 1080))\n","  rectified_image2 = cv.warpPerspective(img2, H2, (1920, 1080))\n","\n","  #visulaze the results\n","  plt.figure(figsize=(25 , 10))  # Adjust width and height as desired\n","  plt.subplot(121),plt.title('rectified_image1'),plt.imshow(rectified_image1)\n","  plt.subplot(122),plt.title('rectified_image2'),plt.imshow(rectified_image2)\n","  plt.show()\n","\n","\n","  # Draw eplines on rectified image_set\n","  # draw epilines on image1 based on points in image2\n","  lines1 = cv.computeCorrespondEpilines(pts2.reshape(-1,1,2), 2,F)\n","  lines1 = lines1.reshape(-1,3)\n","  img5,img6 = drawlines(rectified_image1,rectified_image2,lines1,pts1,pts2)\n","  # draw epilines on image2 based on points in image1\n","  lines2 = cv.computeCorrespondEpilines(pts1.reshape(-1,1,2), 1,F)\n","  lines2 = lines2.reshape(-1,3)\n","  img3,img4 = drawlines(rectified_image2,rectified_image1,lines2,pts2,pts1)\n","\n","  plt.figure(figsize=(25 , 10))  # Adjust width and height as desired\n","  plt.subplot(121),plt.imshow(img5)\n","  plt.subplot(122),plt.imshow(img3)\n","  plt.show()\n","\n","  #finding feature points in rectified images\n","  img1_rectified = rectified_image1\n","  img2_rectified = rectified_image2\n","  # finding feature points for rectified image\n","  sift = cv.SIFT_create()\n","\n","  # find the keypoints and descriptors with SIFT\n","  kp1, des1 = sift.detectAndCompute(img1_rectified,None)\n","  kp2, des2 = sift.detectAndCompute(img2_rectified,None)\n","\n","  # FLANN parameters\n","  FLANN_INDEX_KDTREE = 1\n","  index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n","  search_params = dict(checks=50)\n","\n","  flann = cv.FlannBasedMatcher(index_params,search_params)\n","  matches = flann.knnMatch(des1,des2,k=2)\n","\n","  r_pts1 = []\n","  r_pts2 = []\n","\n","  # ratio test as per Lowe's paper\n","  for i,(m,n) in enumerate(matches):\n","    if m.distance < 0.45*n.distance:\n","        r_pts2.append(kp2[m.trainIdx].pt)\n","        r_pts1.append(kp1[m.queryIdx].pt)\n","\n","  # Now we have the list of best matches from both the images. Let's find the Fundamental Matrix.\n","  r_pts1 = np.int32(pts1)\n","  r_pts2 = np.int32(pts2)\n","  F, mask = cv.findFundamentalMat(pts1,pts2,cv.FM_LMEDS)\n","\n","  print(\"Fundamental_matrix for rectified Images:\",\"\\n\",F)\n","\n","  # We select only inlier points\n","  r_pts1 = pts1[mask.ravel()==1]\n","  r_pts2 = pts2[mask.ravel()==1]\n","\n","  ####################\n","\n","  # Find epilines corresponding to points in right image (second image) and\n","  # drawing its lines on left image\n","  lines1 = cv.computeCorrespondEpilines(pts2.reshape(-1,1,2), 2,F)\n","  lines1 = lines1.reshape(-1,3)\n","  img5,img6 = drawlines(img1_rectified, img2_rectified,lines1,pts1,pts2)\n","\n","  # Find epilines corresponding to points in left image (first image) and\n","  # drawing its lines on right image\n","  lines2 = cv.computeCorrespondEpilines(pts1.reshape(-1,1,2), 1,F)\n","  lines2 = lines2.reshape(-1,3)\n","  img3,img4 = drawlines(img2_rectified, img1_rectified,lines1,pts1,pts2)\n","\n","  plt.figure(figsize=(25 , 10))  # Adjust width and height as desired\n","  plt.subplot(121),plt.imshow(img5)\n","  plt.subplot(122),plt.imshow(img3)\n","  plt.show()\n","\n","  #calculate depth map,disparity map\n","  def compute_depth_image(image1, image2, K1, K2, R, t, baseline):\n","\n","    # Calculate disparity map\n","    # numDisparities=96 # INPUT\n","    numDisparities=number = (ndisp // 16) * 16 # INPUT\n","    print(\"ndisp:\",numDisparities)\n","\n","    stereo = cv.StereoBM_create(numDisparities, blockSize=5)\n","    disparity = stereo.compute(image1, image2)\n","\n","    plt.figure(figsize=(25 , 10))  # Adjust width and height as desired\n","    plt.subplot(121),plt.title('disparity_gray'),plt.imshow(disparity, 'gray')\n","    plt.subplot(122),plt.title('disparity_hot'),plt.imshow(disparity, 'hot')\n","    plt.show()\n","\n","    # Rescale disparity map (assuming maximum disparity is known)\n","\n","    min_val, max_val = 60, 280  # Adjust these values based on your expected disparity range   # INPUT\n","\n","    disparity_scaled = cv.normalize(disparity, None, alpha=255, beta=0, norm_type=cv.NORM_MINMAX, dtype=cv.CV_8U)\n","\n","    # Convert disparity map to color image using heat map conversion\n","    disparity_colored = cv.applyColorMap(disparity_scaled, cv.COLORMAP_JET)\n","\n","    # Compute depth using the formula: depth = baseline * focal length / disparity\n","    f = K1[0, 0]  # Assuming focal length is the same for both cameras\n","    depth_image = baseline * f / (disparity + 1e-6)  # Add a small epsilon to avoid division by zero\n","\n","    # Save disparity image (grayscale and color heatmap)\n","    cv.imwrite(\"disparity_grayscale.png\", disparity_scaled)\n","    jet = cv.applyColorMap(disparity_scaled, cv.COLORMAP_JET)\n","    cv.imwrite(\"disparity_heatmap.png\", jet)\n","\n","    # Save depth image (grayscale and color heatmap)\n","    depth_image_scaled = cv.normalize(depth_image, None, alpha=255, beta=0, norm_type=cv.NORM_MINMAX, dtype=cv.CV_8U)\n","    cv.imwrite(\"depth_grayscale.png\", depth_image_scaled)\n","    jet = cv.applyColorMap(depth_image_scaled, cv.COLORMAP_JET)\n","    cv.imwrite(\"depth_heatmap.png\", jet)\n","\n","    return depth_image, disparity_scaled, depth_image_scaled, disparity_colored\n","\n","  depth_image, disparity_scaled, depth_image_scaled , disparity_colored = compute_depth_image(img1, img2, K1, K2, R, t1, baseline)\n","\n","  # plot the disparity and depth images\n","\n","  plt.figure(figsize=(25 , 10))  # Adjust width and height as desired\n","  plt.subplot(121),plt.title('disparity_scaled_gray'),plt.imshow(disparity_scaled, 'gray')\n","  plt.subplot(122),plt.title('disparity_scaled_colored'),plt.imshow(disparity_colored)\n","  plt.show()\n","\n","  plt.figure(figsize=(25 , 10))  # Adjust width and height as desired\n","  plt.subplot(121),plt.title('depth'),plt.imshow(depth_image, 'gray')\n","  plt.subplot(122),plt.title('depth_scaled'),plt.imshow(depth_image_scaled,'hot')\n","  plt.show()\n"],"metadata":{"id":"phf03nsmKDjh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# LOOP TO CALL PIPELINE FUNCTION FOR EACH IMAGE DATASET\n","i=0\n","for image in image_list:\n","    # print(\"length of image_list:\",len(image_list))\n","    img1,img2 = image\n","    K1, K2 ,baseline, ndisp, vmin, vmax,dataset_no = calib_properties_list[i]\n","    # print(\"calib_data_set_list_no:\",dataset_no)\n","    i+=1\n","    # call function\n","    print(\"Executing Image set:\",i)\n","    pipeline_stereovision(img1,img2,K1,K2,baseline, ndisp,vmin,vmax)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1PTya_NwL5mpvefnEi7zXbHzuWnKEGcaf"},"id":"E4GuypzpKGvi","executionInfo":{"status":"ok","timestamp":1713493416225,"user_tz":240,"elapsed":59404,"user":{"displayName":"Shivam Dhakad","userId":"05137417545652688773"}},"outputId":"c6720e97-705e-4f2b-b982-4e3d0fe9ed37"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO5uHH5DR67Kf04UJXygDEG"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}